{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\swathi\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (0.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (1.14.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from patsy>=0.4.1->category_encoders) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\swathi\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2018.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, log_loss, roc_auc_score\n",
    "!pip install category_encoders\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Demo_Lending_Club.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for initial checks\n",
    "def DF_initial_observations(df):\n",
    "    '''Gives basic details of columns in a dataframe : Data types, distinct values, NAs and sample'''\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        total_na= df.isna().sum().sum()\n",
    "        print('Dimensions : %d rows, %d columns' % (df.shape[0],df.shape[1]))\n",
    "        print(\"Total NA values : %d\" % (total_na))\n",
    "        print('%38s %10s     %10s %10s' % ('Column name', ' Data Type', '# Distinct', ' NA values'))\n",
    "        col_name = df.columns\n",
    "        dtyp = df.dtypes\n",
    "        uniq = df.nunique()\n",
    "        na_val = df.isna().sum()\n",
    "        for i in range(len(df.columns)):\n",
    "            print('%38s %10s :   %10d  %10d' % (col_name[i],dtyp[i],uniq[i],na_val[i]))\n",
    "    else:\n",
    "        print('Expected a DataFrame but got a %15s ' % (type(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions : 10000 rows, 24 columns\n",
      "Total NA values : 15560\n",
      "                           Column name  Data Type     # Distinct  NA values\n",
      "                                    Id      int64 :        10000           0\n",
      "                                is_bad      int64 :            2           0\n",
      "                            emp_length     object :           14           0\n",
      "                        home_ownership     object :            5           0\n",
      "                            annual_inc    float64 :         1901           1\n",
      "                   verification_status     object :            3           0\n",
      "                            pymnt_plan     object :            2           0\n",
      "                           purpose_cat     object :           27           0\n",
      "                              zip_code     object :          720           0\n",
      "                            addr_state     object :           50           0\n",
      "                        debt_to_income    float64 :         2585           0\n",
      "                           delinq_2yrs    float64 :           10           5\n",
      "                        inq_last_6mths    float64 :           20           5\n",
      "                mths_since_last_delinq    float64 :           91        6316\n",
      "                mths_since_last_record    float64 :           94        9160\n",
      "                              open_acc    float64 :           36           5\n",
      "                               pub_rec    float64 :            4           5\n",
      "                             revol_bal      int64 :         8130           0\n",
      "                            revol_util    float64 :         1027          26\n",
      "                             total_acc    float64 :           75           5\n",
      "                   initial_list_status     object :            2           0\n",
      "            collections_12_mths_ex_med    float64 :            1          32\n",
      "           mths_since_last_major_derog      int64 :            3           0\n",
      "                           policy_code     object :            5           0\n"
     ]
    }
   ],
   "source": [
    "DF_initial_observations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeller:\n",
    "    ''' <desc> '''\n",
    "    def __init__(self):\n",
    "        self.num_cols = [] \n",
    "        self.cat_cols = [] \n",
    "        self.model = []\n",
    "        self.params = []\n",
    "        self.cat_encoder = []\n",
    "    \n",
    "    def basic_preprocessing(self, df):\n",
    "        # In attributes like mths_since_last_delinq and mths_since_last_record, absence of data speaks for the non-occurence \n",
    "        # of the acivity (indicating the same by a negative value, -99)\n",
    "        df['mths_since_last_delinq'] = df['mths_since_last_delinq'].fillna(-99)\n",
    "        df['mths_since_last_record'] = df['mths_since_last_record'].fillna(-99)\n",
    "\n",
    "        # coerce emp_length to numeric\n",
    "        df['emp_length'] = pd.to_numeric(df['emp_length'], errors='coerce')\n",
    "\n",
    "        # Extract zip code and convert attribute to numeric\n",
    "        df['zip_code'] = df['zip_code'].str.replace('zip_code_','')\n",
    "        df['zip_code'] = df['zip_code'].str.replace('xx','')\n",
    "        df['zip_code'] = pd.to_numeric(df['zip_code'], downcast='integer')\n",
    "        \n",
    "        self.num_cols = list(df.select_dtypes(exclude=['object']).columns)\n",
    "        self.cat_cols = list(df.select_dtypes(include=['object']).columns)\n",
    "\n",
    "        n = pd.DataFrame(df.isna().sum())\n",
    "        miss_cols = list(n[n[0]>0].index)\n",
    "        miss_num = [*set(miss_cols).intersection(set(self.num_cols))]\n",
    "        miss_cat = [*set(miss_cols).intersection(set(self.cat_cols))]\n",
    "\n",
    "        for i in miss_num:\n",
    "            df[i] = df[i].fillna(df[i].median())\n",
    "        for j in miss_cat:\n",
    "            df[j] = df[j].fillna(df[j].mode()[0])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def fit_encoder(self, df):\n",
    "        ohe = OneHotEncoder()\n",
    "        df_cat = ohe.fit_transform(df[self.cat_cols])\n",
    "        #df_cat = pd.get_dummies(df[self.cat_cols])\n",
    "        self.cat_encoder = ohe\n",
    "        df = pd.concat([df_cat, df[self.num_cols]], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def transform_encoder(self, df):\n",
    "        ohe = self.cat_encoder\n",
    "        df_cat = ohe.transform(df[self.cat_cols])\n",
    "        df = pd.concat([df_cat, df[self.num_cols]], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self.basic_preprocessing(X)\n",
    "        X = self.fit_encoder(X)\n",
    "        if self.params == []:\n",
    "            print('Hyperparameter tuning is due, please try after tuning the parameters')\n",
    "        else:\n",
    "            xg = XGBClassifier(**self.params)\n",
    "            xg.fit(X,y)\n",
    "            self.model = xg\n",
    "\n",
    "    def tune_parameters(self, X, y):\n",
    "        params = {'reg_alpha':[10,50,100],\n",
    "                  'reg_lambda':[10,50,100],\n",
    "                  'learning_rate':[0.01,0.1,0.3],'n_estimators':[10,20,50]}\n",
    "        xg = XGBClassifier(booster='dart', colsample_bylevel=1, n_jobs=-1, \n",
    "                           objective='binary:logistic',eval_metric='logloss', sub_sample=0.8)\n",
    "        grid = GridSearchCV(estimator=xg, param_grid=params, scoring='roc_auc', cv=3, n_jobs=4)\n",
    "        \n",
    "        X = self.basic_preprocessing(X)\n",
    "        X = self.fit_encoder(X)\n",
    "        if X.isna().sum().sum()==0:\n",
    "            grid.fit(X, y)\n",
    "            self.params = grid.best_params_\n",
    "        else:\n",
    "            print('pre-processing is not done')\n",
    "        \n",
    "        return grid.cv_results_\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model == []:\n",
    "            print('fit the model before predict')\n",
    "        else:\n",
    "            X = self.basic_preprocessing(X)\n",
    "            X = self.transform_encoder(X)\n",
    "            pred = self.model.predict(X)\n",
    "        return pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.model == []:\n",
    "            print('fit the model before predict')\n",
    "        else:\n",
    "            X = self.basic_preprocessing(X)\n",
    "            X = self.transform_encoder(X)\n",
    "            pred_prob = self.model.predict_proba(X)\n",
    "        return pred_prob\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        pred = self.predict_proba(X)[1]\n",
    "        f1 = f1_score(y, pred)\n",
    "        ll = log_loss(y, pred)\n",
    "\n",
    "        dt = {'f1_score': f1, 'log_loss': ll}\n",
    "        return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_attr = list(set(df.columns)-set(['id','is_bad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Modeller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\SWATHI\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ml.tune_parameters(X=df[pred_attr], y=df['is_bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.fit(X=df[pred_attr], y=df['is_bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X=df[pred_attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.evaluate(X=df[pred_attr], y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
